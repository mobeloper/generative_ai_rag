{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd7a8e34",
   "metadata": {},
   "source": [
    "## Output Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eb8102",
   "metadata": {},
   "source": [
    "Language models output text. But there are times where you want to get more structured information than just text back\n",
    "\n",
    "Output parsers are classes that help structure language model responses. There are two main methods an output parser must implement:\n",
    "\n",
    "- **Get format instructions**: A method which returns a string containing instructions for how the output of a language model should be formatted.\n",
    "- **Parse**: A method which takes in a string (assumed to be the response from a language model) and parses it into some structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0f4bd7",
   "metadata": {},
   "source": [
    "- Output Parsing\n",
    "    - StrOutputParser\n",
    "    - JsonOutputParser\n",
    "    - CSV Output Parser\n",
    "    - Datatime Output Parser\n",
    "    - Structured Output Parser (Pydanitc or Json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d79f0e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9e05e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "# temperature 0 means the model is factual and we don't want creativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "669c3f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (\n",
    "                                        SystemMessagePromptTemplate,\n",
    "                                        HumanMessagePromptTemplate,\n",
    "                                        ChatPromptTemplate,\n",
    "                                        PromptTemplate\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fa92eb",
   "metadata": {},
   "source": [
    "# Pydantic in LangChain: Notes & Example\n",
    "\n",
    "---\n",
    "\n",
    "## 1. What is Pydantic?\n",
    "\n",
    "- **Pydantic** is a Python library for **data validation** and **settings management** using Python type annotations.\n",
    "- It provides a `BaseModel` class for declaring data models with types, constraints, and descriptions.\n",
    "- It **automatically validates** and parses data, raising errors for missing or invalid fields.\n",
    "\n",
    "**In LangChain, Pydantic models are often used for:**\n",
    "- Defining structured outputs expected from an LLM (e.g., a Joke object, a product recommendation, etc.).\n",
    "- Validating and parsing LLM outputs into safe, strongly-typed Python objects.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Declaring a Pydantic Model\n",
    "\n",
    "```python\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user\"\"\"\n",
    "\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline of the joke\")\n",
    "    rating: Optional[int] = Field(description=\"The rating of the joke is from 1 to 10\", default=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b8bde55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import  Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3f9490",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user\"\"\"\n",
    "\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline of the joke\")\n",
    "    rating: Optional[int] = Field(description=\"The rating of the joke is from 1 to 10\", default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "539f3bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=Joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dd93bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68df3a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Joke to tell user\", \"properties\": {\"setup\": {\"description\": \"The setup of the joke\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"The punchline of the joke\", \"title\": \"Punchline\", \"type\": \"string\"}, \"rating\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"default\": null, \"description\": \"The rating of the joke is from 1 to 10\", \"title\": \"Rating\"}}, \"required\": [\"setup\", \"punchline\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78fd801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    # The 'template' argument defines the format of the prompt to be sent to the LLM.\n",
    "    template='''\n",
    "    Answer the user query with a joke. Here is your formatting instruction.\n",
    "    {format_instruction}\n",
    "\n",
    "    Query: {query}\n",
    "    Answer:''',\n",
    "    \n",
    "    # 'input_variables' specifies which keys the template expects at runtime (here: 'query')\n",
    "    input_variables=['query'],\n",
    "    \n",
    "    # 'partial_variables' are values you want to \"hard-code\" or fill in at creation time.\n",
    "    # Here, format_instruction is filled automatically with instructions from the parser\n",
    "    partial_variables={'format_instruction': parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# The result is a prompt template that, when given a 'query', will fill in both\n",
    "# 'query' (user's actual question) and 'format_instruction' (instructions for output formatting).\n",
    "\n",
    "# Step 2: Create a chain by connecting the prompt template to the LLM\n",
    "# This means: the input dict will first fill the prompt, then be sent to the LLM.\n",
    "chain = prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ead41a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke({'query': 'Tell me a joke about the cat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8084aa93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"setup\": \"Why was the cat sitting on the computer?\",\n",
      "    \"punchline\": \"To keep an eye on the mouse!\",\n",
      "    \"rating\": 8\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caa7c12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup='Why do dogs run in circles before lying down?' punchline=\"Because it's too hard to run in squares!\" rating=8\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "output = chain.invoke({'query': 'Tell me a joke about the dogs'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3692e624",
   "metadata": {},
   "source": [
    "### Parsing with `.with_structured_output()` method\n",
    "- This method takes a schema as input which specifies the names, types, and descriptions of the desired output attributes.\n",
    "-  The schema can be specified as a TypedDict class, JSON Schema or a Pydantic class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90e207e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why was the cat sitting on the computer?\n",
      "\n",
      "Because it wanted to keep an eye on the mouse!\n"
     ]
    }
   ],
   "source": [
    "output = llm.invoke('Tell me a joke about the cat')\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a97b2a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/langchainenv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1547: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "structured_llm = llm.with_structured_output(Joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "246c1f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup='Why was the cat sitting on the computer?' punchline='To keep an eye on the mouse!' rating=8\n"
     ]
    }
   ],
   "source": [
    "output = structured_llm.invoke('Tell me a joke about the cat')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d8e1074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup='Why was the cat sitting on the computer?' punchline='Because it wanted to keep an eye on the mouse!' rating=7\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm2 = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "structured_llm = llm2.with_structured_output(Joke)\n",
    "output = structured_llm.invoke('Tell me a joke about the cat')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04346108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eebceecf",
   "metadata": {},
   "source": [
    "### `JSON` Output Parser\n",
    "\n",
    "- Output parsers accept a string or BaseMessage as input and can return an arbitrary type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8d9b277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Joke to tell user\", \"properties\": {\"setup\": {\"description\": \"The setup of the joke\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"The punchline of the joke\", \"title\": \"Punchline\", \"type\": \"string\"}, \"rating\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"default\": null, \"description\": \"The rating of the joke is from 1 to 10\", \"title\": \"Rating\"}}, \"required\": [\"setup\", \"punchline\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "print(parser.get_format_instructions())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e203fe92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"setup\": \"Why was the cat sitting on the computer?\",\n",
      "    \"punchline\": \"To keep an eye on the mouse!\",\n",
      "    \"rating\": 8\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template='''\n",
    "    Answer the user query with a joke. Here is your formatting instruction.\n",
    "    {format_instruction}\n",
    "\n",
    "    Query: {query}\n",
    "    Answer:''',\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instruction': parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "output = chain.invoke({'query': 'Tell me a joke about the cat'})\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cb33d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'To keep an eye on the mouse!', 'rating': 8}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "output = chain.invoke({'query': 'Tell me a joke about the cat'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466a26c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "100a072c",
   "metadata": {},
   "source": [
    "### CSV Output Parser\n",
    "\n",
    "- This output parser can be used when you want to return a list of comma-separated items.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d67af7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
     ]
    }
   ],
   "source": [
    "# value1, values2, values3, so on\n",
    "\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e511a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instruction = parser.get_format_instructions()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template='''\n",
    "    Answer the user query with a list of values. Here is your formatting instruction.\n",
    "    {format_instruction}\n",
    "\n",
    "    Query: {query}\n",
    "    Answer:''',\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instruction': format_instruction}\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc65cd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP', 'LLM', 'website', 'SEO', 'keywords', 'content']\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "\n",
    "output = chain.invoke({'query': 'generate my website seo keywords. I have content about the NLP and LLM.'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19b6902",
   "metadata": {},
   "source": [
    "### Datatime Output Parser\n",
    "\n",
    "- Gives output in datetime format. Sometimes throws error if the LLM output is not in datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02924635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\n",
      "\n",
      "Examples: 0768-03-18T06:37:13.749146Z, 0740-10-31T18:24:53.376274Z, 0524-08-22T15:37:50.952225Z\n",
      "\n",
      "Return ONLY this string, no other words!\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "\n",
    "parser = DatetimeOutputParser()\n",
    "\n",
    "format_instruction = parser.get_format_instructions()\n",
    "print(format_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "945e97b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template='''\n",
    "    Answer the user query with a datetime. Here is your formatting instruction.\n",
    "    {format_instruction}\n",
    "\n",
    "    Query: {query}\n",
    "    Answer:''',\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instruction': format_instruction}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd60b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33174552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1492-10-12 00:00:00\n"
     ]
    }
   ],
   "source": [
    "output = chain.invoke({'query': 'when the America got discovered?'})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c2ad02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
