{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3c76b049",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "üß™ Assignment: Build a Sentiment Classifier Prompt Pipeline\n",
    "\n",
    "üéØ Objective\n",
    "Create a LangChain-based prompt system that:\n",
    "\n",
    "Explains how sentiment classification works\n",
    "Gives an example (few-shot style)\n",
    "Accepts user input and analyzes it\n",
    "Uses PipelinePromptTemplate to combine everything\n",
    "üìÅ Assignment Tasks\n",
    "‚úÖ Task 1: Introduction Prompt (PromptTemplate)\n",
    "\n",
    "Write a system message that explains the task:\n",
    "‚ÄúYou are a sentiment classifier. Determine if the input is Positive, Negative, or Neutral.‚Äù\n",
    "‚úÖ Task 2: FewShot Example Prompt (FewShotPromptTemplate)\n",
    "\n",
    "Provide 2‚Äì3 example prompts with their expected labels using a few-shot prompt.\n",
    "examples = [\n",
    "    {\"text\": \"The pizza was delicious and perfectly baked!\", \"label\": \"Positive\"},\n",
    "    {\"text\": \"The food was okay, nothing special.\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"The service was terrible and I had to wait an hour.\", \"label\": \"Negative\"}\n",
    "]\n",
    "Use an example template like:\n",
    "\n",
    "example_template = PromptTemplate.from_template(\"Input: {text}\\nSentiment: {label}\\n\")\n",
    "‚úÖ Task 3: Execution Prompt (PromptTemplate)\n",
    "\n",
    "Prompt the user to enter new input and format it as:\n",
    "\"Now analyze this review:\\nInput: {input_text}\\nSentiment:\"\n",
    "‚úÖ Task 4: Build a PipelinePromptTemplate\n",
    "\n",
    "Use PipelinePromptTemplate to combine the following:\n",
    "\n",
    "Introduction\n",
    "FewShotPrompt\n",
    "Execution Prompt\n",
    "‚úÖ Task 5: Use ChatPromptTemplate and LLMChain\n",
    "\n",
    "Use ChatPromptTemplate or PromptTemplate with an LLM (like gpt-4o-mini) to:\n",
    "\n",
    "Format the prompt using the pipeline\n",
    "Send the prompt and return the sentiment\n",
    "üí° Bonus Task (Optional)\n",
    "Accept live input from the user using input() or a loop\n",
    "Generate sentiment analysis interactively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62cef964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14cac2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Libraries\n",
    "from langchain.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6692fd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Introduction Prompt\n",
    "introduction_template = \"You are a sentiment classifier. Determine if the input is Positive, Neutral, or Negative.\"\n",
    "introduction_prompt = PromptTemplate.from_template(introduction_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "369dea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Few-Shot Examples Prompt\n",
    "examples = [\n",
    "    {\"text\": \"The pizza was delicious and perfectly baked!\", \"label\": \"Positive\"},\n",
    "    {\"text\": \"The food was okay, nothing special.\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"The service was terrible and I had to wait an hour.\", \"label\": \"Negative\"}\n",
    "]\n",
    "\n",
    "example_template = PromptTemplate.from_template(\"Input: {text}\\nSentiment: {label}\\n\")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_template,\n",
    "    prefix=\"Here are some examples:\",\n",
    "    suffix=\"\",\n",
    "    input_variables=[]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b0d460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Execution Prompt\n",
    "execution_template = \"Now analyze this review:\\nInput: {input_text}\\nSentiment:\"\n",
    "execution_prompt = PromptTemplate.from_template(execution_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea150141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g1/5_fr35dx4bg267_nq27dz3tw0000gn/T/ipykernel_80514/1046937676.py:10: LangChainDeprecationWarning: This class is deprecated. Please see the docstring below or at the link for a replacement option: https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.pipeline.PipelinePromptTemplate.html\n",
      "  pipeline_prompt = PipelinePromptTemplate(\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Combine using PipelinePromptTemplate\n",
    "final_template = \"\"\"{intro}\n",
    "\n",
    "{examples}\n",
    "\n",
    "{execution}\"\"\"\n",
    "\n",
    "final_prompt = PromptTemplate.from_template(final_template)\n",
    "\n",
    "pipeline_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=final_prompt,\n",
    "    pipeline_prompts=[\n",
    "        (\"intro\", introduction_prompt),\n",
    "        (\"examples\", few_shot_prompt),\n",
    "        (\"execution\", execution_prompt)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40a7b65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Output:\n",
      " Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Create Chain and Run\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "chain = LLMChain(llm=llm, prompt=pipeline_prompt)\n",
    "\n",
    "# Run a test input\n",
    "input_text = \"The ambiance was great, but the food was underwhelming.\"\n",
    "result = chain.invoke({\"input_text\": input_text})\n",
    "\n",
    "print(\"LLM Output:\\n\", result[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4881084a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
