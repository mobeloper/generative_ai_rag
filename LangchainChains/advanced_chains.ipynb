{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chains with multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cc/_kcvjw313pl6kbf8c3bdtnyc0000gn/T/ipykernel_81219/1191947449.py:8: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt_template)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'a parrot',\n",
       " 'text': 'Why did the parrot wear a raincoat?\\n\\nBecause it wanted to be a poly-ester!'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=1)\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"input\"], template=\"Tell me a joke about {input}\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "chain.invoke(input=\"a parrot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'a parrot',\n",
       " 'language': 'hindi',\n",
       " 'text': '‡§è‡§ï ‡§Ü‡§¶‡§Æ‡•Ä ‡§®‡•á ‡§è‡§ï ‡§§‡•ã‡§§‡§æ ‡§ñ‡§∞‡•Ä‡§¶‡§æ‡•§ ‡§µ‡§π ‡§§‡•ã‡§§‡§æ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§¨‡§æ‡§§‡•á‡§Ç ‡§ï‡§∞‡§§‡§æ ‡§•‡§æ‡•§ \\n\\n‡§Ü‡§¶‡§Æ‡•Ä: \"‡§§‡•Ç ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à?\"\\n\\n‡§§‡•ã‡§§‡§æ: \"‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡•á ‡§Æ‡§æ‡§≤‡§ø‡§ï ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ö‡§æ‡§Ø ‡§¨‡§®‡§æ‡§§‡§æ ‡§π‡•Ç‡§Å!\"\\n\\n‡§Ü‡§¶‡§Æ‡•Ä: \"‡§Ö‡§ö‡•ç‡§õ‡§æ! ‡§§‡•ã ‡§´‡§ø‡§∞ ‡§§‡•Å‡§ù‡•á ‡§ö‡§æ‡§Ø ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡§æ ‡§Æ‡§ú‡§æ ‡§Ü‡§Ø‡§æ?\"\\n\\n‡§§‡•ã‡§§‡§æ: \"‡§®‡§π‡•Ä‡§Ç, ‡§ö‡§æ‡§Ø ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§π‡§∞ ‡§¨‡§æ‡§∞ ‡§§‡•Å‡§Æ ‡§Æ‡•Å‡§ù‡•á ‡§¨‡•á‡§ï‡§æ‡§∞ ‡§∏‡§Æ‡§ù‡§§‡•á ‡§π‡•ã!\" üòÑ'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(input_variables=[\"input\", \"language\"], template=\"Tell me a joke about {input} in {language}\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "chain.invoke({\"input\": \"a parrot\", \"language\": \"hindi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chains can be more complex and not all sequential chains will be as simple as passing a single string as an argument and getting a single string as output for all steps in the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.sequential import SequentialChain\n",
    "\n",
    "# This is an LLMChain to write a review given a dish name and the experience.\n",
    "prompt_review = PromptTemplate.from_template(\n",
    "    template=\"You ordered {dish_name} from {restaurantName} and your experience was {experience}. Write a review: \"\n",
    ")\n",
    "chain_review = LLMChain(llm=llm, prompt=prompt_review, output_key=\"review\")\n",
    "\n",
    "#=============================================================================================================\n",
    "\n",
    "# This is an LLMChain to write a follow-up comment given the restaurant review.\n",
    "prompt_comment = PromptTemplate.from_template(\n",
    "    template=\"Given the restaurant review: {review}, write a follow-up comment: \"\n",
    ")\n",
    "chain_comment = LLMChain(llm=llm, prompt=prompt_comment, output_key=\"comment\")\n",
    "\n",
    "#==============================================================================================================\n",
    "\n",
    "# This is an LLMChain to summarize a review.\n",
    "prompt_summary = PromptTemplate.from_template(\n",
    "    template=\"Summarise the review in one short sentence: \\n\\n {comment}\"\n",
    ")\n",
    "chain_summary = LLMChain(llm=llm, prompt=prompt_summary, output_key=\"summary\")\n",
    "\n",
    "#================================================================================================================\n",
    "\n",
    "# This is an LLMChain to translate a summary into German.\n",
    "prompt_translation = PromptTemplate.from_template(\n",
    "    template=\"\"\"    \n",
    "    Translate the summary to 3 languages: \n",
    "    1. Hindi\n",
    "    2. Spanish\n",
    "    3. French\n",
    "    \\n\\n {summary}\n",
    "    \"\"\"\n",
    ")\n",
    "chain_translation = LLMChain(\n",
    "    llm=llm, prompt=prompt_translation, output_key=\"lang_translation\"\n",
    ")\n",
    "\n",
    "#=================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dish_name': 'Chicken Biryani',\n",
       " 'restaurantName': 'Akbar Biryani',\n",
       " 'experience': 'It was awful!',\n",
       " 'review': \"**Review of Chicken Biryani from Akbar Biryani**\\n\\nRating: ‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ\\n\\nI recently ordered Chicken Biryani from Akbar Biryani, and I must say that my experience was nothing short of disappointing. From the moment the dish arrived, I had a sinking feeling that I was in for a letdown.\\n\\nFirst and foremost, the aroma, which is usually a highlight of a good biryani, was underwhelming. The spices seemed muted, and there was none of that delightful, fragrant scent that you typically expect from this classic dish. When I finally opened the container, I was greeted by a presentation that was far from appealing. The rice looked clumpy and oddly colored, lacking the vibrant hues one associates with perfectly cooked biryani.\\n\\nMoving on to the chicken, I was surprised at how tough and dry it was. It's fair to say that it felt more like an afterthought than the star of the dish. In addition, the portion size was small for the price I paid, leaving me feeling quite dissatisfied.\\n\\nAs for the taste, it was bland and lacked the depth of flavors that truly good biryani brings to the table. I expected a harmonious blend of spices and tender meat, but what I got was an unfortunate mishmash that I couldn't even finish.\\n\\nMoreover, the accompanying raita was uninspiring and did little to salvage the meal. Overall, my experience with Akbar Biryani was a letdown, and I left feeling regretful about my choice. I had high hopes for this dish, but it simply did not deliver. I won't be ordering from Akbar Biryani again anytime soon.\",\n",
       " 'comment': \"I'm really sorry to hear about your experience at Akbar Biryani. It‚Äôs always disappointing when a meal doesn‚Äôt live up to expectations, especially something as beloved as Chicken Biryani. The lack of aroma and flavor can really ruin the whole experience, and tough, dry chicken is never a good sign. It sounds like they need to revisit their recipe or cooking methods! Have you considered sharing this feedback directly with the restaurant? Sometimes, restaurants appreciate constructive criticism, and it might help them improve. In the meantime, if you have any recommendations for places that do serve a great Chicken Biryani, I‚Äôd love to hear them!\",\n",
       " 'summary': 'The review expresses disappointment with the Chicken Biryani at Akbar Biryani, citing issues with flavor and texture, and suggests providing feedback to the restaurant for improvement.',\n",
       " 'lang_translation': 'Sure! Here‚Äôs the translation of the summary into the requested languages:\\n\\n1. **Hindi:**\\n   ‡§∏‡§Æ‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§Ö‡§ï‡•Ä‡§¨‡§∞ ‡§¨‡§ø‡§∞‡§Ø‡§æ‡§®‡•Ä ‡§Æ‡•á‡§Ç ‡§ö‡§ø‡§ï‡§® ‡§¨‡§ø‡§∞‡§Ø‡§æ‡§®‡•Ä ‡§∏‡•á ‡§®‡§ø‡§∞‡§æ‡§∂‡§æ ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§ ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à, ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§∏‡•ç‡§µ‡§æ‡§¶ ‡§î‡§∞ ‡§¨‡§®‡§æ‡§µ‡§ü ‡§∏‡•á ‡§ú‡•Å‡§°‡§º‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§ú‡§ø‡§ï‡•ç‡§∞ ‡§π‡•à, ‡§î‡§∞ ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§¶‡•á‡§§‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∞‡•á‡§∏‡•ç‡§ü‡•ã‡§∞‡•á‡§Ç‡§ü ‡§ï‡•ã ‡§´‡•Ä‡§°‡§¨‡•à‡§ï ‡§¶‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§è‡•§\\n\\n2. **Spanish:**\\n   La rese√±a expresa decepci√≥n con el Chicken Biryani en Akbar Biryani, citando problemas con el sabor y la textura, y sugiere proporcionar comentarios al restaurante para su mejora.\\n\\n3. **French:**\\n   La critique exprime sa d√©ception concernant le Chicken Biryani chez Akbar Biryani, √©voquant des probl√®mes de saveur et de texture, et sugg√®re de donner des retours au restaurant pour une am√©lioration.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_review, chain_comment, chain_summary, chain_translation],\n",
    "    input_variables=[\"dish_name\",\"restaurantName\",\"experience\"],\n",
    "    output_variables=[\"review\", \"comment\", \"summary\", \"lang_translation\"],\n",
    ")\n",
    "\n",
    "overall_chain.invoke({\"dish_name\": \"Chicken Biryani\", \"restaurantName\":\"Akbar Biryani\", \"experience\": \"It was awful!\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of chaining multiple chains together we can also use an LLM to decide which follow up chain is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "\n",
    "positive_template = \"\"\"You are an AI that focuses on the positive side of things. \\\n",
    "Whenever you analyze a text, you look for the positive aspects and highlight them. \\\n",
    "Here is the text:\n",
    "{input}\"\"\"\n",
    "\n",
    "neutral_template = \"\"\"You are an AI that has a neutral perspective. You just provide a balanced analysis of the text, \\\n",
    "not favoring any positive or negative aspects. Here is the text:\n",
    "{input}\"\"\"\n",
    "\n",
    "negative_template = \"\"\"You are an AI that is designed to find the negative aspects in a text. \\\n",
    "You analyze a text and show the potential downsides. Here is the text:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"positive\",\n",
    "        \"description\": \"Good for analyzing positive sentiments\",\n",
    "        \"prompt_template\": positive_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"neutral\",\n",
    "        \"description\": \"Good for analyzing neutral sentiments\",\n",
    "        \"prompt_template\": neutral_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"negative\",\n",
    "        \"description\": \"Good for analyzing negative sentiments\",\n",
    "        \"prompt_template\": negative_template,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are an AI that focuses on the positive side of things. Whenever you analyze a text, you look for the positive aspects and highlight them. Here is the text:\\n{input}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x1166a6d10>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x116637290>, root_client=<openai.OpenAI object at 0x116634790>, root_async_client=<openai.AsyncOpenAI object at 0x116685210>, model_name='gpt-4o-mini', temperature=1.0, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}),\n",
       " 'neutral': LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are an AI that has a neutral perspective. You just provide a balanced analysis of the text, not favoring any positive or negative aspects. Here is the text:\\n{input}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x1166a6d10>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x116637290>, root_client=<openai.OpenAI object at 0x116634790>, root_async_client=<openai.AsyncOpenAI object at 0x116685210>, model_name='gpt-4o-mini', temperature=1.0, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}),\n",
       " 'negative': LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are an AI that is designed to find the negative aspects in a text. You analyze a text and show the potential downsides. Here is the text:\\n{input}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x1166a6d10>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x116637290>, root_client=<openai.OpenAI object at 0x116634790>, root_async_client=<openai.AsyncOpenAI object at 0x116685210>, model_name='gpt-4o-mini', temperature=1.0, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={})}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# prompt_infos is expected to be a list of dictionaries, each containing at least \"name\" and \"prompt_template\" keys.\n",
    "# For each prompt info:\n",
    "#   Extract the name and prompt template.\n",
    "#   Create a PromptTemplate object that takes one input variable called \"input\".\n",
    "#   Create an LLMChain: This is an LLM + a prompt. So, each \"destination\" (e.g., \"food_review\", \"hotel_review\", etc.) gets its own LLMChain.\n",
    "#   Store each chain in the destination_chains dictionary, keyed by its name.\n",
    "\n",
    "# Result: A dictionary where each key is a destination name and each value is a ready-to-use LLMChain for that intent.\n",
    "    \n",
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "destination_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive: Good for analyzing positive sentiments\n",
      "neutral: Good for analyzing neutral sentiments\n",
      "negative: Good for analyzing negative sentiments\n"
     ]
    }
   ],
   "source": [
    "# For each prompt in prompt_infos, create a string like \"food_review: Handles food related reviews\".\n",
    "# Combine all such strings into a newline-separated list (destinations_str).\n",
    "# Print it for debugging. This will help the router know what all \"destinations\" it can send queries to.\n",
    "\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "print(destinations_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cc/_kcvjw313pl6kbf8c3bdtnyc0000gn/T/ipykernel_81219/677733521.py:26: LangChainDeprecationWarning: Please see migration guide here for recommended implementation: https://python.langchain.com/docs/versions/migrating_chains/multi_prompt_chain/\n",
      "  chain = MultiPromptChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive: {'input': 'I ordered Pizza Salami for $9.99 and it was awesome!'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'I ordered Pizza Salami for $9.99 and it was awesome!',\n",
       " 'text': \"That's fantastic! It's wonderful to hear that you enjoyed your Pizza Salami so much. The price of $9.99 is quite reasonable for a delicious meal. It's great when you can treat yourself to something tasty and have a positive experience with your order!\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a predefined template (MULTI_PROMPT_ROUTER_TEMPLATE) that expects the available destinations.\n",
    "# Plug in the list of destinations you just built.\n",
    "# Build a PromptTemplate for the router, which will use the user input and output a routing decision.\n",
    "# Set the output_parser to RouterOutputParser() (this parses the router‚Äôs decision).\n",
    "\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "\n",
    "# Create a Router Chain that will use your LLM and the router prompt.\n",
    "# When given an input, it decides which destination chain (from step 1) to route the input to.\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n",
    "\n",
    "\n",
    "# MultiPromptChain is the master orchestrator.\n",
    "# It uses:\n",
    "# The router chain to select a destination.\n",
    "# The dictionary of destination chains.\n",
    "# A default chain (for \"neutral\" or unknown inputs).\n",
    "# verbose=True gives you logs as it routes and processes.\n",
    "\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=destination_chains[\"neutral\"],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.invoke({\"input\": \"I ordered Pizza Salami for 9.99$ and it was awesome but awful !\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
